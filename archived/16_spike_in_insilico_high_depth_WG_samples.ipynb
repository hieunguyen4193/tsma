{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9aab8b94-3db8-4508-a36c-4ff8d6455261",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on 1-CONTROLCF3ME131W_M504-M704_spike_in__01_Breast_4.deduplicated.bam\n",
      "sorting bam file\n",
      "indexing bam file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[E::hts_open_format] Failed to open file \"/mnt/archiving/DATA_HIEUNHO/Spike_in/121023_cfDNA_highdepth_control/batch127/merge_spike_in/1-CONTROLCF3ME131W_M504-M704_spike_in__01_Breast_4.deduplicated.sorted.bam\" : No such file or directory\n",
      "samtools index: failed to open \"/mnt/archiving/DATA_HIEUNHO/Spike_in/121023_cfDNA_highdepth_control/batch127/merge_spike_in/1-CONTROLCF3ME131W_M504-M704_spike_in__01_Breast_4.deduplicated.sorted.bam\": No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method format of str object at 0x7fa85b288ad0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                  | 0/2945 [00:00<?, ?it/s]\u001b[A[E::idx_find_and_load] Could not retrieve index file for '/mnt/archiving/DATA_HIEUNHO/Spike_in/121023_cfDNA_highdepth_control/batch127/merge_spike_in/1-CONTROLCF3ME131W_M504-M704_spike_in__01_Breast_4.deduplicated.bam'\n",
      "  0%|                                                  | 0/2945 [00:00<?, ?it/s]\n",
      "  0%|                                                   | 0/300 [00:17<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "fetch called on bamfile without index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 127\u001b[0m\n\u001b[1;32m    125\u001b[0m         os\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamtools index \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m -@ 100\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(path_to_bam\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.bam\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.sorted.bam\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeconvolution samplename \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat)\n\u001b[0;32m--> 127\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mdeconvo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbamfile\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpath_to_bam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_to_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_to_16_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSampleID\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataframe(data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinished_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(SampleID)], columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheck\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[1;32m    130\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path_to_16_output, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheck_finished_Sample_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(SampleID))\n\u001b[1;32m    131\u001b[0m )\n",
      "Cell \u001b[0;32mIn[29], line 50\u001b[0m, in \u001b[0;36mdeconvo\u001b[0;34m(bamfile, path_to_output)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m region \u001b[38;5;129;01min\u001b[39;00m tqdm(atlas_regions):\n\u001b[1;32m     49\u001b[0m     region \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(region\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m], region\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m], region\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m---> 50\u001b[0m     bamfile_obj \u001b[38;5;241m=\u001b[39m \u001b[43mpysam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAlignmentFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbamfile\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregion\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mregion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     reads \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m read \u001b[38;5;129;01min\u001b[39;00m bamfile_obj:\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.8/site-packages/pysam/libcalignmentfile.pyx:1098\u001b[0m, in \u001b[0;36mpysam.libcalignmentfile.AlignmentFile.fetch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: fetch called on bamfile without index"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pysam\n",
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "from helper_functions import *\n",
    "outputdir = \"./outputdir_02102023\"\n",
    "\n",
    "topK = 500\n",
    "atlas_sample_types = \"Tissue,WBC\"\n",
    "\n",
    "path_to_03_output = os.path.join(outputdir, \"03_output_noFDR\")\n",
    "path_to_04_output = os.path.join(outputdir, \"04_output_noFDR\", \"top{}_{}\".format(topK, atlas_sample_types.replace(\",\", \"_and_\")))\n",
    "path_to_05_output = os.path.join(outputdir, \"05_output_noFDR\", \"top{}_{}\".format(topK, atlas_sample_types.replace(\",\", \"_and_\")))\n",
    "path_to_06_output = os.path.join(outputdir, \"06_output_noFDR\", \"top{}_{}\".format(topK, atlas_sample_types.replace(\",\", \"_and_\")))\n",
    "path_to_07_output = os.path.join(outputdir, \"07_output_noFDR\", \"top{}_{}\".format(topK, atlas_sample_types.replace(\",\", \"_and_\")))\n",
    "path_to_08_output = os.path.join(outputdir, \"08_output_noFDR\", \"top{}_{}\".format(topK, atlas_sample_types.replace(\",\", \"_and_\")))\n",
    "path_to_10_output = os.path.join(outputdir, \"10_output_noFDR\", \"top{}_{}\".format(topK, atlas_sample_types.replace(\",\", \"_and_\")))\n",
    "\n",
    "path_to_16_output = os.path.join(outputdir, \"16_output_noFDR\", \"top{}_{}\".format(topK, atlas_sample_types.replace(\",\", \"_and_\")))\n",
    "os.system(\"mkdir -p {}\".format(path_to_16_output))\n",
    "\n",
    "metadata = pd.read_csv(\"/datassd/hieunho/Spike_in/metadata.csv\")\n",
    "\n",
    "datadir = \"/mnt/archiving/DATA_HIEUNHO/Spike_in/121023_cfDNA_highdepth_control\"\n",
    "\n",
    "atlas = pd.read_csv(os.path.join(path_to_03_output, \"top{}_atlas_{}.final.csv\".format(topK, atlas_sample_types)), index_col =[0])\n",
    "\n",
    "atlas = atlas[[item for item in atlas.columns if \"_y\" not in item ]]\n",
    "atlas.columns = [item.replace(\"_x\", \"\") for item in atlas.columns]\n",
    "\n",
    "avg_atlas = atlas.set_index(\"sample\").fillna(0).groupby(\"label\").mean()\n",
    "avg_atlas = avg_atlas.loc[atlas_labels[atlas_sample_types]]\n",
    "atlas_regions = [item for item in atlas.columns if item not in [\"sample\", \"label\"]]\n",
    "\n",
    "def deconvo(bamfile, path_to_output):    \n",
    "    os.system(\"mkdir -p {}\".format(path_to_output))\n",
    "    \n",
    "    samplename = bamfile.split(\"/\")[-1]\n",
    "    \n",
    "    if (os.path.isfile(os.path.join(path_to_output, \"Sample_{}.deconvo.csv\".format(samplename))) == False):\n",
    "        output_readdf = pd.DataFrame()\n",
    "        for region in tqdm(atlas_regions):\n",
    "            region = \"{}:{}-{}\".format(region.split(\"_\")[0], region.split(\"_\")[1], region.split(\"_\")[2])\n",
    "            bamfile_obj = pysam.AlignmentFile(bamfile).fetch(region = region)\n",
    "            \n",
    "            reads = []\n",
    "            for read in bamfile_obj:\n",
    "                reads.append(read)\n",
    "            readdf = pd.DataFrame()\n",
    "            readdf[\"chrom\"] = [read.to_dict()[\"ref_name\"] for read in reads]\n",
    "            readdf[\"start\"] = [read.to_dict()[\"ref_pos\"] for read in reads]\n",
    "            readdf[\"cigar\"] = [read.to_dict()[\"cigar\"] for read in reads]\n",
    "            readdf[\"flen\"] = [read.to_dict()[\"length\"] for read in reads]\n",
    "            readdf[\"seq\"] = [read.to_dict()[\"seq\"] for read in reads]\n",
    "            readdf[\"methyl_string\"] = [read.to_dict()[\"tags\"][2] for read in reads]\n",
    "            readdf[\"XR\"] = [read.to_dict()[\"tags\"][3] for read in reads]\n",
    "            readdf[\"XG\"] = [read.to_dict()[\"tags\"][4] for read in reads]\n",
    "            readdf[\"sample\"] = samplename\n",
    "            readdf[\"region\"] = region\n",
    "            output_readdf = pd.concat([output_readdf, readdf], axis = 0)\n",
    "        output_readdf.to_csv(os.path.join(path_to_output, \"Sample_{}.csv\".format(samplename)))\n",
    "        \n",
    "        \n",
    "        all_betadf = pd.DataFrame(data = [samplename], columns = [\"sample\"])\n",
    "        for region in tqdm(atlas_regions):\n",
    "            df = output_readdf[output_readdf[\"region\"] == \"{}:{}-{}\".format(region.split(\"_\")[0],\n",
    "                                                             region.split(\"_\")[1],\n",
    "                                                             region.split(\"_\")[2])]\n",
    "            region_chrom = region.split(\"_\")[0]\n",
    "            region_start = int(region.split(\"_\")[1])\n",
    "            region_end = int(region.split(\"_\")[2])\n",
    "            refseq_at_cluster = get_refseq(path_to_all_fa = path_to_all_fa, \n",
    "                                                chrom = region_chrom, \n",
    "                                                start = region_start, \n",
    "                                                end = region_end + 1)\n",
    "            all_cpg_in_cluster = [m.start(0) for m in re.finditer(\"CG\", refseq_at_cluster)]\n",
    "            cpg_coords = [item + region_start for item in all_cpg_in_cluster]\n",
    "            \n",
    "            df[\"check_cigar\"] = df[\"cigar\"].apply(lambda x: bool(pattern.fullmatch(x)))\n",
    "            df = df[df[\"check_cigar\"] == True]\n",
    "            \n",
    "            if df.shape[0] != 0:\n",
    "                df[\"end\"] = df[[\"start\", \"cigar\"]].apply(lambda x: int(x[0]) + int(x[1].replace(\"M\", \"\")), axis = 1)\n",
    "                df[\"start\"] = df[\"start\"].astype(int)\n",
    "                df[\"end\"] = df[\"end\"].astype(int)\n",
    "                for cpg_pos in cpg_coords:\n",
    "                    df[cpg_pos] = df[[\"start\", \"end\", \"seq\"]].apply(lambda x: get_CpG_status(x[0], x[1], x[2], cpg_pos, mode = \"num\"), axis = 1)\n",
    "                \n",
    "                betadf = pd.DataFrame(data = [samplename], columns = [\"sample\"])\n",
    "                \n",
    "                for cpg_pos in cpg_coords:    \n",
    "                    tmpdf = df[[\"sample\", cpg_pos]].copy()\n",
    "                    tmpcountdf = tmpdf.groupby('sample')[cpg_pos].apply(lambda x: (x == 1).sum()/((x == 0).sum() + (x == 1).sum()) ).reset_index(name= \"meth_level_{}\".format(cpg_pos))\n",
    "                    betadf = betadf.merge(tmpcountdf[[\"sample\", \"meth_level_{}\".format(cpg_pos)]], right_on = \"sample\", left_on = \"sample\", how = \"outer\")\n",
    "                \n",
    "                betadf[\"avg_beta\"] = betadf[[item for item in betadf.columns if item != \"sample\"]].apply(lambda x: np.mean([item for item in x if np.isnan(item) == False]), axis = 1)\n",
    "                betadf = betadf[[\"sample\", \"avg_beta\"]]\n",
    "                betadf.columns = [\"sample\", region]\n",
    "                all_betadf = all_betadf.merge(betadf[[\"sample\", region]], right_on = \"sample\", left_on = \"sample\")\n",
    "        deconvo_res_cfdna = deconvo(all_betadf, avg_atlas, atlas_sample_types)\n",
    "        \n",
    "        deconvo_res_cfdna.to_csv(os.path.join(path_to_output, \"Sample_{}.deconvo.csv\".format(samplename)))\n",
    "    return deconvo_res_cfdna\n",
    "\n",
    "SampleID = \"1-CONTROLCF3ME131W_M504-M704\"\n",
    "\n",
    "if os.path.isfile(os.path.join(path_to_16_output, \"check_finished_Sample_{}.csv\".format(SampleID))) == False:\n",
    "    os.system(\"mkdir -p {}\".format(os.path.join(path_to_16_output, SampleID)))\n",
    "    \n",
    "    paths = [item for item in pathlib.Path(datadir).glob('*/merge_spike_in/{}_spike_in*.deduplicated.bam'.format(SampleID))]\n",
    "    for path_to_bam in tqdm(paths):\n",
    "        samplename = path_to_bam.name\n",
    "        print(\"working on {}\".format(path_to_bam.name))\n",
    "        path_to_bam = str(path_to_bam)\n",
    "        if os.path.isfile(path_to_bam.replace(\".bam\", \".sorted.bam\") + \".bai\") == False:\n",
    "            print(\"sorting bam file\")\n",
    "            os.system(\"samtools sort {} -@ 100 -o {}\".format(path_to_bam, path_to_bam.replace(\".bam\", \".sorted.bam\")))\n",
    "            print(\"indexing bam file\")\n",
    "            os.system(\"samtools index {} -@ 100\".format(path_to_bam.replace(\".bam\", \".sorted.bam\")))\n",
    "        print(\"deconvolution samplename {}\".format)\n",
    "        _ = deconvo(bamfile = path_to_bam.replace(\".bam\", \".sorted.bam\"), path_to_output = os.path.join(path_to_16_output, SampleID))\n",
    "    \n",
    "    pd.Dataframe(data = [\"finished_{}\".format(SampleID)], columns = [\"check\"]).to_csv(\n",
    "        os.path.join(path_to_16_output, \"check_finished_Sample_{}.csv\".format(SampleID))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a3692dc-ef43-4398-b640-c79959afaed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'samtools sort /mnt/archiving/DATA_HIEUNHO/Spike_in/121023_cfDNA_highdepth_control/batch127/merge_spike_in/1-CONTROLCF3ME131W_M504-M704_spike_in__01_Breast_4.deduplicated.bam -@ 100 -o /mnt/archiving/DATA_HIEUNHO/Spike_in/121023_cfDNA_highdepth_control/batch127/merge_spike_in/1-CONTROLCF3ME131W_M504-M704_spike_in__01_Breast_4.deduplicated.sorted.bam'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"samtools sort {} -@ 100 -o {}\".format(path_to_bam, path_to_bam.replace(\".bam\", \".sorted.bam\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
